<!doctype html>
<html lang="English">
<head>
<meta charset="utf-8">
<meta name="generator" content="pandoc">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Inferred Preference Model: Methods & Sources</title>

<!-- Yahoo! CDN combo URL for selected Pure.css modules -->
<link rel="stylesheet" href="http://yui.yahooapis.com/combo?pure/0.6.0/base-min.css&pure/0.6.0/grids-responsive-min.css&pure/0.6.0/menus-min.css&pure/0.6.0/tables-min.css">
<!-- MathJax -->
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<!-- Vega and Vega Embed -->
<script src="https://cdn.jsdelivr.net/npm/vega@4.4.0"></script>
<script src="https://cdn.jsdelivr.net/npm/vega-lite@3.0.0-rc11"></script>
<script src="https://cdn.jsdelivr.net/npm/vega-embed@3.28.0"></script>

<!-- Extra styles -->
<style>
body{margin:10em 0 0}.pure-g{padding:0 1em}.pure-menu-link:focus{background-color:#d3d3d3}nav{margin:0 0 1em;padding:0 0 1em;border-bottom:1px solid #ccc}footer{margin:5em 0 1em}pre{white-space:pre-wrap;margin-left:3em}code{font-size:89%;color:#191919}.author{margin-bottom:0;padding-bottom:0}.headnote,.published,.license{font-size:89%;margin-bottom:.75em}@media screen and (max-width:35.5em){thead{display:none}tr,th,td{display:block}td{border-top:0}tr td:first-child{border-top:1px solid #ddd;font-weight:700}}
table {
    margin-left: auto;
    margin-right: auto;
    margin-bottom: 24px;
    border-spacing: 0;
    border-bottom: 2px solid black;
    border-top: 2px solid black;
}
table th {
    padding: 3px 10px;
    background-color: white;
    border-top: none;
    border-left: none;
    border-right: none;
    border-bottom: 1px solid black;
}
table td {
    padding: 3px 10px;
    border-top: none;
    border-left: none;
    border-bottom: none;
    border-right: none;
}
</style>

<script src="" type="text/javascript"></script>
</head>
<body>
<section id="page-content">
<div class="pure-g">
<div class="pure-u-1 pure-u-sm-1 pure-u-md-1 pure-u-lg-1 pure-u-xl-1">

<!-- page content begins here -->

<section id="preference-model-notes" class="level2">
<h2>Preference-Model Notes</h2>
<p>Our goal is to use the house election results<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> to fit a very simple model of the electorate. We consider the electorate as having some number of "identity" groups. For example we could divide by sex (the census only records this as a F/M binary), age, "old" (45 or older) and "young" (under 45) and racial identity (white-non-hispanic or non-white). We recognize that these categories are limiting and much too simple. But we believe it's a reasonable starting point, as a balance between inclusiveness and having way too many variables.</p>
<p>For each congressional district where both major parties ran candidates, we have census estimates of the number of people in each of our demographic categories<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>. And from the census we have national-level turnout estimates for each of these groups as well<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>. We assume that these turnout percentages hold exactly in each district, giving a number of voters, <span class="math inline">\(N\)</span>, in each group, <span class="math inline">\(i\)</span>, for each district.</p>
<p>All we can observe is the <strong>sum</strong> of all the votes in the district, not the ones cast by each group separately. But each district has a different demographic makeup and so each is a distinct piece of data about how each group is likely to vote.</p>
<p>What we want to estimate, is how likely a voter in each group is of voting for the democratic candidate in a contested race.</p>
<p>For each district, <span class="math inline">\(d\)</span>, we have the set of expected voters (the number of people in each group, multiplied by the turnout for that group), <span class="math inline">\(\{V_i\}_d\)</span>, the number of democratic votes, <span class="math inline">\(D_d\)</span>, republican votes, <span class="math inline">\(R_d\)</span> and total votes, <span class="math inline">\(T_d\)</span>, which may exceed <span class="math inline">\(D_d + R_d\)</span>, since there may be third party candidates. For the sake of simplicity, we assume that all groups are equally likely to vote for a third party candidate. We want to estimate <span class="math inline">\(p_i\)</span>, the probability that a voter (in any district) in the <span class="math inline">\(i\)</span>th group--given that they voted for a republican or democrat--will vote for the democratic candidate.</p>
<ul>
<li><p>Bayes theorem<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a> relates the probability of a model (our demographic voting probabilities <span class="math inline">\(\{p_i\}\)</span>), given the observed data (the number of democratic votes recorded in each district, <span class="math inline">\(\{D_k\}\)</span>) to the likelihood of observing that data given the model and some prior knowledge about the unconditional probability of the model itself <span class="math inline">\(P(\{p_i\})\)</span>, as well as <span class="math inline">\(P(\{D_k\})\)</span>, the unconditional probability of observing the "evidence": <span class="math inline">\(\begin{equation} P(\{p_i\}|\{D_k\})P(\{D_k\}) = P(\{D_k\}|\{p_i\})P(\{p_i\}) \end{equation}\)</span> In this situation, the thing we wish to compute, <span class="math inline">\(P(\{p_i\}|\{D_k\})\)</span>, is referred to as the "posterior" distribution.</p></li>
<li><p><span class="math inline">\(P(\{p_i\})\)</span> is called a "prior" and amounts to an assertion about what we think we know about the parameters before we have seen any of the data. In practice, this can often be set to something very boring, in our case, we will assume that our prior is just that any <span class="math inline">\(p_i \in [0,1]\)</span> is equally likely.</p></li>
<li><p><span class="math inline">\(P(\{D_k\})\)</span> is the unconditional probability of observing the specific outcome <span class="math inline">\(\{D_k\}\)</span> This is difficult to compute! Sometimes we can compute it by observing: <span class="math inline">\(\begin{equation} P(\{D_k\}) = \sum_{\{p_i\}} P(\{D_k\}|{p_i}) P(\{p_i\}) \end{equation}\)</span>. But in general, we'd like to compute the posterior in some way that avoids needing the probability of the evidence.</p></li>
<li><p><span class="math inline">\(P(\{D_k\}|\{p_i\})\)</span>, the probability that we observed our evidence, <em>given</em> a specific set of <span class="math inline">\(\{p_i\}\)</span> is a thing we can calculate: Our <span class="math inline">\(p_i\)</span> are the probability that one voter of type <span class="math inline">\(i\)</span>, who votes for a democrat or republican, chooses the democrat. We <em>assume</em>, for the sake of simplicity, that for each demographic group <span class="math inline">\(i\)</span>, each voter's vote is like a coin flip where the coin comes up "Democrat" with probability <span class="math inline">\(p_i\)</span> and "Republican" with probability <span class="math inline">\(1-p_i\)</span>. This distribution of single voter outcomes is known as the <a href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli distribution.</a>. Given <span class="math inline">\(V_i\)</span> voters of that type, the distribution of democratic votes <em>from that type of voter</em> is <a href="https://en.wikipedia.org/wiki/Binomial_distribution">Binomial</a> with <span class="math inline">\(V_i\)</span> trials and <span class="math inline">\(p_i\)</span> probability of success. But <span class="math inline">\(V_i\)</span> is quite large! So we can approximate this with a normal distribution with mean <span class="math inline">\(V_i p_i\)</span> and variance <span class="math inline">\(V_i p_i (1 - p_i)\)</span> (see <a href="https://en.wikipedia.org/wiki/Binomial_distribution#Normal_approximation">Wikipedia</a>). However, we can't observe the number of votes from just one type of voter. We can only observe the sum over all types. Luckily, the sum of normally distributed random variables follows a normal distribution as well. So the distribution of democratic votes across all types of voters is also normal, with mean <span class="math inline">\(\sum_i V_i p_i\)</span> and variance <span class="math inline">\(\sum_i V_i p_i (1 - p_i)\)</span> (again, see <a href="https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables">Wikipedia</a>). Thus we have <span class="math inline">\(P(D_k|\{p_i\})\)</span>, or, what amounts to the same thing, its probability density. But that means we also know the probability density of all the evidence given <span class="math inline">\(\{p_i\}\)</span>, <span class="math inline">\(\rho(\{D_k\}|\{p_i\})\)</span>, since that is just the product of the densities for each <span class="math inline">\(D_k\)</span>: <span class="math inline">\(\begin{equation} \mu_k(\{p_i\}) = \sum_i V_i p_i\\ v_k(\{p_i\}) = \sum_i V_i p_i (1 - p_i)\\ \rho(D_k|\{p_i\}) = \frac{1}{\sqrt{2\pi v_k}}e^{-\frac{(D_k -\mu_k(\{p_i\}))^2}{2v_k(\{p_i\})}}\\ \rho(\{D_k\}|\{p_i\}) = \Pi_k \rho(D_k|\{p_i\}) \end{equation}\)</span></p></li>
<li><p>In order to compute expectations on this distribution we use Markov Chain Monte Carlo (MCMC). MCMC creates "chains" of samples from the the posterior distribution given a prior, <span class="math inline">\(P(\{p_i\})\)</span>, the conditional <span class="math inline">\(P(\{D_k\}|\{p_i\})\)</span>, and a starting <span class="math inline">\(\{p_i\}\)</span>. Note that this doesn't require knowing <span class="math inline">\(P(\{D_k\})\)</span>, basically because the <em>relative</em> likelihood of any <span class="math inline">\(\{p_i\}\)</span> doesn't depend on it. Those samples are then used to compute expectations of various quantities of interest. In practice, it's hard to know when you have "enough" samples to have confidence in your expectations. Here we use an interval based "potential scale reduction factor" (<a href="http://www2.stat.duke.edu/~scs/Courses/Stat376/Papers/ConvergeDiagnostics/BrooksGelman.pdf">PSRF</a>) to check the convergence of any one expectation, e,g, each <span class="math inline">\(p_i\)</span> in <span class="math inline">\(\{p_i\}\)</span>, and a "multivariate potential scale reduction factor" (<a href="https://www.ets.org/Media/Research/pdf/RR-03-07-Sinharay.pdf">MPSRF</a>) to make sure that the convergence holds for all possible linear combinations of the <span class="math inline">\(\{p_i\}\)</span>. Calculating either PSRF or MPSRF entails starting several chains from different (random) starting locations, then comparing something like a variance on each chain to the same quantity on the combined chains. This converges to one as the chains converge<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a> and a value below 1.1 is, conventionally, taken to indicate that the chains have converged "enough".</p></li>
</ul>
</section>
<section class="footnotes" role="doc-endnotes">
<hr />
<ol>
<li id="fn1" role="doc-endnote"><p>MIT Election Data and Science Lab, 2017 , "U.S. House 1976–2018" , https://doi.org/10.7910/DVN/IG0UN2 , Harvard Dataverse, V3 , UNF:6:KlGyqtI+H+vGh2pDCVp7cA== [fileUNF]<a href="#fnref1" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn2" role="doc-endnote"><p>Source: US Census, American Community Survey <a href="https://www.census.gov/programs-surveys/acs.html" class="uri">https://www.census.gov/programs-surveys/acs.html</a><a href="#fnref2" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn3" role="doc-endnote"><p>Source: US Census, Voting and Registration Tables <a href="https://www.census.gov/topics/public-sector/voting/data/tables.2014.html" class="uri">https://www.census.gov/topics/public-sector/voting/data/tables.2014.html</a>. NB: We are using 2017 demographic population data for our 2018 analysis, since that is the latest available from the census. We will update this once the census publishes updated 2018 American Community Survey data.<a href="#fnref3" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn4" role="doc-endnote"><p><a href="https://en.wikipedia.org/wiki/Bayes%27_theorem" class="uri">https://en.wikipedia.org/wiki/Bayes%27_theorem</a><a href="#fnref4" class="footnote-back" role="doc-backlink">↩</a></p></li>
<li id="fn5" role="doc-endnote"><p>The details of this convergence are beyond our scope but just to get an intuition: consider a PSRF computed by using (maximum - minimum) of some quantity. The mean of these intervals is also the mean maximum minus the mean minimum. And the mean maximum is clearly less than the maximum across all chains while the mean minimum is clearly larger than than the absolute minimum across all chains. So their ratio gets closer to 1 as the individual chains look more and more like the combined chain, which we take to mean that the chains have converged.<a href="#fnref5" class="footnote-back" role="doc-backlink">↩</a></p></li>
</ol>
</section>

<!-- page content ends here -->

</div>     <!-- pure-u-1... -->
</div>     <!-- pure-g -->
</section> <!-- page-content -->
<div class="pure-g">
<footer><a href="https://bitfragment.github.io/mindoc">mindoc</a> v1.1.0</footer>
</div>
<script>
var mindoc=function(){function e(e){return e=e.toLowerCase(),e.charAt(0).toUpperCase()+e.substr(1)}function n(e){var n=new RegExp(/^\b[a-z]\S+\b-\b\S+\b/);return n.test(e)&&(e=e.replace(/-+/g," ")),e}function t(t){return t=n(t),e(t)}function r(e,n){return!!e.className.match(new RegExp("(\\s|^)"+n+"(\\s|)"))}function a(e,n){r(e,n)||(e.className+=" "+n)}function o(e,n){if(r(e,n)){var t=new RegExp("(\\s|^)"+n+"(\\s|)");e.className=e.className.replace(t," ")}}function u(){var e,n,t={table:"pure-table pure-table-bordered"};Object.keys(t).forEach(function(r){if(e=document.getElementsByTagName(r),n=e.length,n>1)for(var o=0;n>o;o++)a(e[o],t[r])})}function c(e,n){for(var t=0,r=e.length;r>t;t++)for(var a=e[t].getElementsByTagName("a"),u=0,c=a.length;c>u;u++)a[u].addEventListener("click",function(){o(n,"hidden")})}function i(e,n){for(var t=0,r=e.length;r>t;t++)e[t].addEventListener("click",function(){o(n,"hidden")})}function d(){var e=document.createElement("li");return a(e,"pure-menu-item"),e}function l(e){var n=document.createElement("a");return n.id="menu-"+e,n.href="#",n.innerHTML=t(e),a(n,"pure-menu-link"),n}function m(e){var n=document.createDocumentFragment(),t=document.createElement("nav"),r=document.createElement("div"),o=document.createElement("ul");n.appendChild(t),t.appendChild(r),r.appendChild(o),a(r,"pure-menu"),a(o,"pure-menu-list");var u="All sections",c=d();a(c,"pure-menu-selected"),o.appendChild(c),c.appendChild(l(u));for(var i,m,s=0,f=e.length;f>s;s++)i=e[s].getAttribute("id"),m=d(),o.appendChild(m),m.appendChild(l(i));var p=document.getElementById("page-content");document.querySelector("body").insertBefore(n,p)}function s(e){var n;e.hasAttribute("pure-menu-selected")||(n=document.querySelector(".pure-menu-selected"),o(n,"pure-menu-selected"),a(e,"pure-menu-selected"))}function f(e,n){var t,u=n.getAttribute("id"),c=u.replace(/menu-/,""),i=document.getElementById(u).parentNode;s(i);for(var d in e)t=e[d],r(t,"hidden")||a(t,"hidden"),t.getAttribute("id")===c&&r(t,"hidden")&&o(t,"hidden")}function p(e){var n;for(var t in e)n=e[t],r(n,"hidden")&&o(n,"hidden")}function v(e){for(var n=document.querySelectorAll(".pure-menu-link"),t=0,r=n.length;r>t;t++)0===t?n[t].addEventListener("click",function(){p(e)}):n[t].addEventListener("click",function(){f(e,this)})}return{main:function(){if(u(),document.getElementsByClassName("level2").length>0){var e,n=[];["abstract","level2","footnotes"].forEach(function(t){e=document.getElementsByClassName(t);for(var r=0,a=e.length;a>r;r++)n.push(e[r])});var t;for(var o in n)t=n[o],r(t,"level2")||a(t,"level2"),r(t,"footnotes")&&t.setAttribute("id","footnotes");m(n),v(n);var d=document.getElementsByClassName("citation"),l=document.getElementById("references");c(d,l);var s=document.getElementsByClassName("footnoteRef"),f=document.getElementById("footnotes");i(s,f)}}}}();window.addEventListener("load",function(){mindoc.main()});
</script>

<!-- For debugging local scripts -->
<!-- <script src="../build/mindoc.js"></script> -->
</body>
</html>
